# review_analysis/crawling/naver_crawler.py

from review_analysis.crawling.base_crawler import BaseCrawler
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
import time
import csv
import os
import re

class NaverCrawler(BaseCrawler):
    """
    Naver Smart Storeì˜ ì œí’ˆ ë¦¬ë·°ë¥¼ í¬ë¡¤ë§í•˜ëŠ” í´ë˜ìŠ¤.

    íŠ¹ì • ìƒí’ˆ URLì— ì ‘ì†í•˜ì—¬, ìµœëŒ€ 500ê°œì˜ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•˜ê³ ,
    ë‚ ì§œ, ë³„ì , ë¦¬ë·° ë³¸ë¬¸ì„ í¬í•¨í•œ ë°ì´í„°ë¥¼ ì €ì¥í•œë‹¤.

    Attributes:
        url (str): í¬ë¡¤ë§ ëŒ€ìƒ Naver Smart Store ìƒí’ˆ í˜ì´ì§€ URL
        reviews (list): ìˆ˜ì§‘ëœ ë¦¬ë·° ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸
    """

    def __init__(self, output_dir: str):
        super().__init__(output_dir)
        self.url = "https://brand.naver.com/cocacola/products/4624572909"
        self.reviews = []

    def start_browser(self):
        """
        í¬ë¡¬ ë¸Œë¼ìš°ì €ë¥¼ ìë™ìœ¼ë¡œ ì„¤ì • ë° ì‹¤í–‰í•œë‹¤.

        - ìë™í™” íƒì§€ ë°©ì§€ ì„¤ì •
        - ì‚¬ìš©ì ì—ì´ì „íŠ¸ ì„¤ì •
        - webdriver-managerë¥¼ ì´ìš©í•œ í¬ë¡¬ ë“œë¼ì´ë²„ ìë™ ì„¤ì¹˜
        """
        options = Options()
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument("user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)")
        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service, options=options)

        self.driver.execute_cdp_cmd(
            'Page.addScriptToEvaluateOnNewDocument',
            {
                'source': '''
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => false
                    })
                '''
            }
        )

    def scrape_reviews(self):
        """
        Naver Smart Store ë¦¬ë·°ë¥¼ ìµœëŒ€ 500ê°œê¹Œì§€ í¬ë¡¤ë§í•œë‹¤.

        - ê° í˜ì´ì§€ì—ì„œ ìŠ¤í¬ë¡¤ì„ ë‚´ë ¤ ëª¨ë“  ë¦¬ë·°ë¥¼ ë¡œë“œ
        - ë¦¬ë·°ì˜ ë³„ì , ë‚ ì§œ, ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ
        - ë¦¬ë·° ìˆ˜ì§‘ì´ ì™„ë£Œë˜ë©´ í˜ì´ì§€ë¥¼ ì´ë™í•˜ë©° ë°˜ë³µ
        - '1~10 â†’ ë‹¤ìŒ â†’ 11~20 â†’ ë‹¤ìŒ ...' í˜•íƒœì˜ í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜ ì²˜ë¦¬
        """
        self.start_browser()
        self.driver.get(self.url)
        time.sleep(3)

        current_page = 1

        while len(self.reviews) < 500:
            print(f"ğŸ“„ {current_page} í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘...")

            # ìŠ¤í¬ë¡¤í•´ì„œ ë¦¬ë·° ë¡œë“œ (í•œ í˜ì´ì§€ ë‚´ì—ì„œ ì „ì²´ ë¦¬ë·° ë¡œë“œ)
            for _ in range(20):
                self.driver.execute_script("window.scrollBy(0, 3000);")
                time.sleep(1.5)

            # ë³„ì ê³¼ ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ì¶œ

            stars = self.driver.find_elements(By.CLASS_NAME, "_15NU42F3kT")[4:]
            spans = self.driver.find_elements(By.CLASS_NAME, "_2L3vDiadT9")

            spans_text = [s.text.strip() for s in spans]  # WebElementì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            date_pattern = re.compile(r'\d{2}\.\d{2}\.\d{2}\.')

            # ë‚ ì§œ ì¸ë±ìŠ¤ ì°¾ê¸°
            date_indices = [i for i, text in enumerate(spans_text) if date_pattern.fullmatch(text)]

            # ì•ë¶€ë¶„ ì œê±°
            first_index = date_indices[0]
            spans_text = spans_text[first_index:]
            date_indices = [i - first_index for i in date_indices]


            # ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
            groups = []
            for idx, start in enumerate(date_indices):
                end = date_indices[idx + 1] if idx + 1 < len(date_indices) else len(spans_text)
                groups.append(spans_text[start:end])

            # í•œ í˜ì´ì§€ ë‹¹ 20ê°œ í¬ë¡¤ë§
            for i in range(0,19):
                try:
                    star = stars[i].text
                    date = groups[i][0]
                    content = groups[i][-2]
                    self.reviews.append([date, star, content])
                except Exception as e:
                    print(f"âŒ ë¦¬ë·° {i} íŒŒì‹± ì‹¤íŒ¨:", e)

                    # 500ê°œ ëª¨ì•˜ìœ¼ë©´ ì¢…ë£Œ
                    if len(self.reviews) >= 500:
                        break

            # 20ë²ˆì§¸
            self.reviews.append([groups[19][0], stars[19].text, groups[19][-1]])
            

            # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
            try:

                if current_page%10 > 0 :
                    next_button = self.driver.find_element(By.XPATH, f'//a[text()="{current_page + 1}"]')
                    self.driver.execute_script("arguments[0].click();", next_button)
                    current_page += 1
                    time.sleep(3)
                else :
                    next_button = self.driver.find_element(By.XPATH, '//a[text()="ë‹¤ìŒ"]')
                    self.driver.execute_script("arguments[0].click();", next_button)
                    current_page += 1
                    time.sleep(3)
            except Exception as e:
                print("âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ê±°ë‚˜ 'ë‹¤ìŒ' ë²„íŠ¼ ì—†ìŒ:", e)
                break

        self.driver.quit()



    def save_to_database(self):
        """
        ìˆ˜ì§‘í•œ ë¦¬ë·° ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•œë‹¤.

        ì €ì¥ ê²½ë¡œëŠ” ì´ˆê¸°í™” ì‹œ ì„¤ì •ëœ `output_dir`ì— `"naver_reviews.csv"`ë¡œ ì €ì¥ëœë‹¤.
        íŒŒì¼ ì¸ì½”ë”©ì€ `utf-8-sig`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—‘ì…€ì—ì„œë„ í•œê¸€ì´ ê¹¨ì§€ì§€ ì•Šë„ë¡ ì²˜ë¦¬í•¨.
        """
        os.makedirs(self.output_dir, exist_ok=True)
        output_path = os.path.join(self.output_dir, "reviews_naver.csv")

        with open(output_path, "w", newline="", encoding="utf-8-sig") as f:
            writer = csv.writer(f)
            writer.writerow(["ë‚ ì§œ", "ë³„ì ", "ë¦¬ë·°"])
            writer.writerows(self.reviews)

        print(f"âœ… {len(self.reviews)}ê°œ ë¦¬ë·° ì €ì¥ ì™„ë£Œ: {output_path}")

